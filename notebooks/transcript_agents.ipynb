{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstuts_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "def set_api_key_if_not_present(key_name, prompt_message=\"\"):\n",
    "    if len(prompt_message) == 0:\n",
    "        prompt_message=key_name\n",
    "    if key_name not in os.environ or not os.environ[key_name]:\n",
    "        os.environ[key_name] = getpass.getpass(prompt_message)\n",
    "\n",
    "set_api_key_if_not_present(\"OPENAI_API_KEY\")\n",
    "set_api_key_if_not_present(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class ApplicationParameters:\n",
    "    filename = \"data/test.json\"\n",
    "    embedding_model = \"text-embedding-3-small\"\n",
    "    tool_calling_model = \"gpt-4.1-mini\"\n",
    "    n_context_docs = 2\n",
    "\n",
    "params = ApplicationParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "class PsTutsTeamState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: List[str]\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tool_calling = ChatOpenAI(model=params.tool_calling_model,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "adobe_help_search = TavilySearchResults(max_results=5,include_domains=[\"helpx.adobe.com\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pstuts_rag.agents import create_agent, agent_node\n",
    "\n",
    "adobe_help_agent = create_agent(\n",
    "    llm_tool_calling,\n",
    "    [adobe_help_search],\n",
    "    \"You are a research assistant who can search\"\n",
    "    \"for Adobe Photoshop help topics using the tavily search engine.\"\n",
    "    \"Users may provide you with partial questions - try your best to determine their intent.\"\n",
    "    \"If sending a request to search, craft your query so that it enhances user's ability\"\n",
    "    \"to receive a helpful answer.\",\n",
    ")\n",
    "adobe_help_node = functools.partial(agent_node, agent=adobe_help_agent, name=\"AdobeHelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval = adobe_help_agent.invoke({\"question\":\"What are layers?\",\"messages\":[],\"team_members\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are layers?',\n",
       " 'messages': [],\n",
       " 'team_members': [],\n",
       " 'output': 'You can find comprehensive Adobe Photoshop help topics and user guides on the official Adobe website. These cover a wide range of subjects including color management, web and screen design, video and animation, nondestructive editing, layers and groups, masks, Smart Filters, blending modes, and more.\\n\\nHere are some useful links to explore:\\n- Common questions about Photoshop on the web: https://helpx.adobe.com/photoshop/using/photoshop-web-faq.html\\n- Photoshop User Guide: https://helpx.adobe.com/photoshop/user-guide.html\\n- Photoshop tools, options, and task bars: https://helpx.adobe.com/photoshop/using/using-tools.html\\n- View all Adobe Photoshop tutorials: https://helpx.adobe.com/in/photoshop/view-all-tutorials.filter-bar.html#!topic-title\\n\\nThese resources provide detailed instructions and tutorials to help you with various Photoshop features and tasks.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "First, we will read in the transcripts of the videos and convert them to Documents\n",
    "with appropriate metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import Dict\n",
    "import json\n",
    "\n",
    "from pstuts_rag.loader import load_json_files\n",
    "filename = [\"../data/test.json\"]\n",
    "from typing import List, Dict, Any\n",
    "data:List[Dict[str,Any]] = await load_json_files(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R - retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's hit it with a semantic chunker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pstuts_rag.datastore import DatastoreManager\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(path=\":memory:\")\n",
    "\n",
    "retriever_factory = DatastoreManager(qdrant_client=client,name=\"local_test\")\n",
    "if retriever_factory.count_docs() == 0:\n",
    "    await retriever_factory.populate_database(raw_docs=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "We will use a 4.1-nano to generate answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import tool\n",
    "from pstuts_rag.rag import RAGChainFactory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "rag_factory = RAGChainFactory(retriever=retriever_factory.get_retriever())\n",
    "get_videos = rag_factory.get_rag_chain(llm=ChatOpenAI(model=params.tool_calling_model))\n",
    "\n",
    "@tool\n",
    "def get_videos_call(\n",
    "    query: Annotated[str, \"Query to pose to Photoshop training video transcript archive\"]\n",
    "    ):\n",
    "  \"\"\"Extract information from Photoshop training video archive.\"\"\"\n",
    "  return get_videos.invoke({\"question\" : query})\n",
    "\n",
    "get_videos_agent = create_agent(\n",
    "  llm_tool_calling,\n",
    "  [get_videos_call],\n",
    "  \"\"\"You are an expert trainer in Adobe Photoshop who\n",
    "  has an archive of training videos at her disposal.\n",
    "  You can request transcripts of those videos and then summarize and shape \n",
    "  them to provide helpful answers.\"\"\"\n",
    ")\n",
    "\n",
    "get_videos_node = functools.partial(agent_node, \n",
    "                                    agent=get_videos_agent,\n",
    "                                    name=\"VideoArchiveSearch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Layers in Photoshop are like separate flat pieces of glass stacked on top of each other, where each layer contains its own separate content. This allows you to work on different parts of an image independently. For example, you can toggle the visibility of each layer on or off to see what content it holds. Transparent areas in a layer let you see through to the layers below. This stacking and independence are the biggest benefits of using layers‚Äîyou can edit one part of an image without affecting others. You can see all layers and work with them in the Layers panel. (See 0:28‚Äì2:00 and 1:25‚Äì2:32 for details) üé®üñºÔ∏è\\n**REFERENCES**\\n[\\n  {\\n    \"title\": \"Understand layers\",\\n    \"source\": \"https://images-tv.adobe.com/avp/vr/b758b4c4-2a74-41f4-8e67-e2f2eab83c6a/f810fc5b-2b04-4e23-8fa4-5c532e7de6f8/e268fe4d-e5c7-415c-9f5c-d34d024b14d8_20170727011753.1280x720at2400_h264.mp4\",\\n    \"start\": 0.47,\\n    \"stop\": 62.14\\n  },\\n  {\\n    \"title\": \"Understand layers\",\\n    \"source\": \"https://images-tv.adobe.com/avp/vr/b758b4c4-2a74-41f4-8e67-e2f2eab83c6a/f810fc5b-2b04-4e23-8fa4-5c532e7de6f8/e268fe4d-e5c7-415c-9f5c-d34d024b14d8_20170727011753.1280x720at2400_h264.mp4\",\\n    \"start\": 85.75,\\n    \"stop\": 152.97\\n  }\\n]', additional_kwargs={'refusal': None, 'context': [Document(metadata={'video_id': 19172, 'title': 'Understand layers', 'desc': 'Learn what layers are and why they are so useful.', 'length': '00:04:44.75', 'group': 'test.json', 'source': 'https://images-tv.adobe.com/avp/vr/b758b4c4-2a74-41f4-8e67-e2f2eab83c6a/f810fc5b-2b04-4e23-8fa4-5c532e7de6f8/e268fe4d-e5c7-415c-9f5c-d34d024b14d8_20170727011753.1280x720at2400_h264.mp4', 'speech_start_stop_times': [[0.47, 3.41], [3.81, 9.13], [9.309999, 15.01], [15.299999, 20.57], [20.88, 23.3], [23.83, 27.93], [29.38, 32.79], [32.96, 33.92], [34.43, 40.21], [41.91, 45.37], [45.88, 49.01], [49.54, 55.130001], [55.72, 58.49], [58.72, 62.14]], 'start': 0.47, 'stop': 62.14, '_id': 21, '_collection_name': 'local_test'}, page_content=\"Layers are the building blocks of any image in Photoshop CC. So, it's important to understand, what layers are and why to use them - which we'll cover in this video. If you're following along, open this layered image from the downloadable practice files for this tutorial. You might think of layers like separate flat pints of glass, stacked one on top of the other. Each layer contains separate pieces of content. To get a sense of how layers are constructed, let's take a look at this Layers panel. I've closed my other panels, so that we can focus on the Layers panel. But you can skip that. By the way: If your Layers panel isn't showing, go up to the Window menu and choose Layers from there. The Layers panel is where you go to select and work with layers. In this image there are 4 layers, each with separate content. If you click the Eye icon to the left of a layer, you can toggle the visibility of that layer off and on. So, I'm going to turn off the visibility of the tailor layer. And keep your eye on the image, so you can see what's on that layer.\"), Document(metadata={'video_id': 19172, 'title': 'Understand layers', 'desc': 'Learn what layers are and why they are so useful.', 'length': '00:04:44.75', 'group': 'test.json', 'source': 'https://images-tv.adobe.com/avp/vr/b758b4c4-2a74-41f4-8e67-e2f2eab83c6a/f810fc5b-2b04-4e23-8fa4-5c532e7de6f8/e268fe4d-e5c7-415c-9f5c-d34d024b14d8_20170727011753.1280x720at2400_h264.mp4', 'speech_start_stop_times': [[85.75, 88.659999], [89.42, 100.11], [101.469999, 108.64], [109.09, 117.459999], [117.75, 129.45], [129.97, 133.37], [133.73, 143.98], [144.76, 152.97]], 'start': 85.75, 'stop': 152.97, '_id': 23, '_collection_name': 'local_test'}, page_content=\"Now let's take a look at just one layer, the tailor layer. A quick way to turn off all the layers except the tailor layer, is to hold down the Option key on the Mac, or the ALT key on the PC, and click on the Eye icon to the left of the tailor layer. In the Document window, you can see that this layer contains just the one small photo surrounded by a gray and white checkerboard pattern. That pattern represents transparent pixels, which allow us to see down through the corresponding part of this layer to the content of the layers below. So, let's turn that content back on by going back to the Layers panel, again holding the Option key on the Mac or the ALT key on the PC and clicking on the Eye icon to the left of the tailor layer. And all the other layers and their Eye icons come back into view. So again: You might think of layers like a stack of pints of glass, each with its own artwork and in some cases transparent areas that let you see down through to the layers below. The biggest benefit of having items on separate layers like this, is that you'll be able to edit pieces of an image independently without affecting the rest of the image.\")], 'question': 'What are layers?'}, response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 1446, 'total_tokens': 1586, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'finish_reason': 'stop', 'logprobs': None}, id='run--767b8147-ec59-4767-a6d3-8e7b54a89e4f-0', usage_metadata={'input_tokens': 1446, 'output_tokens': 140, 'total_tokens': 1586, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retval = get_videos_call.invoke(\"What are layers?\")\n",
    "retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = await get_videos.ainvoke({\"question\":\"What are layers\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pstuts_rag.agents import create_team_supervisor\n",
    "supervisor_agent = create_team_supervisor(\n",
    "    llm_tool_calling,\n",
    "    \"\"\"You are the Supervisor for an agentic RAG system. Your job is to interpret the user‚Äôs request, extract the core research topic, and decide which research-focused worker to invoke next. Reply only with the next worker and the subject to research, or FINISH when the workflow is complete.\n",
    "\n",
    "Workers\n",
    "‚Ä¢ VideoArchiveSearch ‚Äì retrieves videos related to the query  \n",
    "‚Ä¢ AdobeHelp         ‚Äì searches Adobe‚Äôs documentation and training resources  \n",
    "\n",
    "Routing Rules\n",
    "1. Topic Extraction  \n",
    "   ‚Ä¢ Read the user‚Äôs request and identify a concise research topic (e.g. ‚ÄúPhotoshop timeline keyframes‚Äù).\n",
    "\n",
    "2. Primary Preference  \n",
    "   ‚Ä¢ First invoke VideoArchiveSearch with that topic.  \n",
    "   ‚Ä¢ If VideoArchiveSearch returns ‚ÄúI don‚Äôt know‚Äù or ‚Äúno results,‚Äù fall back to AdobeHelp.\n",
    "\n",
    "3. AdobeHelp Behavior  \n",
    "   ‚Ä¢ When routing to AdobeHelp, always also check for related training videos in Adobe‚Äôs library.\n",
    "\n",
    "4. Research-Only  \n",
    "   ‚Ä¢ Only invoke workers that perform research tasks.\n",
    "\n",
    "5. Completion  \n",
    "   ‚Ä¢ When neither worked can provide value, go to FINISH. If AdobeHelp\n",
    "   expands the list of topics, make sure to attempt to search for them with the\n",
    "   VideoArchiveSearch.\n",
    "\n",
    "Response Format\n",
    "<WorkerName>: <Research Topic>\n",
    "\n",
    "Example:\n",
    "VideoArchiveSearch: exporting vector layers from After Effects\n",
    "\n",
    "And, once there‚Äôs no further research needed:\n",
    "FINISH\n",
    "\"\"\",\n",
    "    [\"VideoArchiveSearch\", \"AdobeHelp\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "adobe_help_graph = StateGraph(PsTutsTeamState)\n",
    "\n",
    "adobe_help_graph.add_node(\"VideoArchiveSearch\", get_videos_node)\n",
    "adobe_help_graph.add_node(\"AdobeHelp\", adobe_help_node)\n",
    "adobe_help_graph.add_node(\"supervisor\", supervisor_agent)\n",
    "\n",
    "edges = [\n",
    "    [\"VideoArchiveSearch\",\"supervisor\"],\n",
    "    [\"AdobeHelp\",\"supervisor\"],\n",
    "]\n",
    "\n",
    "[adobe_help_graph.add_edge(*p) for p in edges]\n",
    "\n",
    "adobe_help_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x:x[\"next\"],\n",
    "    {\"VideoArchiveSearch\":\"VideoArchiveSearch\",\n",
    "    \"AdobeHelp\":\"AdobeHelp\",    \n",
    "    \"FINISH\": END},\n",
    ")\n",
    "adobe_help_graph.set_entry_point(\"supervisor\")\n",
    "adobe_help_compiled = adobe_help_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    }
   ],
   "source": [
    "adobe_help_graph.set_entry_point(\"supervisor\")\n",
    "compiled_research_graph = adobe_help_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            +-----------+                             \n",
      "                            | __start__ |                             \n",
      "                            +-----------+                             \n",
      "                                  *                                   \n",
      "                                  *                                   \n",
      "                                  *                                   \n",
      "                            +------------+                            \n",
      "                            | supervisor |                            \n",
      "                       *****+------------+.....                       \n",
      "                   ****            *           ....                   \n",
      "              *****                *               .....              \n",
      "           ***                     *                    ...           \n",
      "+-----------+           +--------------------+           +---------+  \n",
      "| AdobeHelp |           | VideoArchiveSearch |           | __end__ |  \n",
      "+-----------+           +--------------------+           +---------+  \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.graph_ascii import draw_ascii\n",
    "\n",
    "graph_data = compiled_research_graph.get_graph()\n",
    "print(graph_data.draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_chain(message: str):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"team_members\": [\"VideoArchiveSearch\", \"AdobeHelp\"],\n",
    "    }\n",
    "    return results\n",
    "\n",
    "research_chain = enter_chain | compiled_research_graph\n",
    "\n",
    "def demo_research_chain(query:str):\n",
    "    \n",
    "    for s in research_chain.stream(\n",
    "        query, \n",
    "        {\"recursion_limit\": 20}\n",
    "    ):\n",
    "        if \"__end__\" not in s:\n",
    "            if 'supervisor' not in s.keys():\n",
    "                for response in s.values():\n",
    "                    for msg in response['messages']:\n",
    "                        msg.pretty_print()\n",
    "            else:\n",
    "                print(s)\n",
    "            print(\"---\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'VideoArchiveSearch'}}\n",
      "---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: VideoArchiveSearch\n",
      "\n",
      "Layers in Photoshop are like separate flat panes of glass stacked on top of each other, with each layer containing separate pieces of content. You can think of them as the building blocks of any image. In the Layers panel, you can see all the layers in your image, each with an Eye icon to toggle its visibility on or off, allowing you to see or hide that layer's content.\n",
      "\n",
      "A single layer can have transparent pixels, shown as a gray and white checkerboard pattern, which lets you see through to the layers beneath it. You can also hold down the Option key (Mac) or ALT key (PC) and click the Eye icon next to a layer to hide all other layers except the one you clicked on, focusing only on that layer. Doing the same action again will bring all other layers back into view.\n",
      "\n",
      "The main benefit of using layers is that you can edit parts of your image independently without affecting other layers, giving you great flexibility in your editing process.\n",
      "---\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "demo_research_chain(\"What are layers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
